{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb7a53-4daf-4cfd-8a55-a00e91b21d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.stats import ks_2samp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# --- Config ---\n",
    "input_dir = \"/Users/artemis/Desktop/bdt/bdt_inputs\"\n",
    "output_dir = \"/Users/artemis/Desktop/bdt/bdt_results_0l/boosted_\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define signal files per regime\n",
    "signal_files_map = {\n",
    "    \"boosted\": [\n",
    "        \"bdt_ZH12.root\", \"bdt_ZH15.root\",\"bdt_ZH20.root\", \"bdt_ZH25.root\", \"bdt_ZH30.root\"\n",
    "    ],\n",
    "   \n",
    "    \"resolved\": [\n",
    "        \"bdt_ZH30.root\", \"bdt_ZH40.root\", \"bdt_ZH50.root\", \"bdt_ZH60.root\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Glob all background files (QCD, TT, Zto)\n",
    "background_patterns = [\"bdt_QCD800.root\",\"bdt_QCD1000.root\",\"bdt_QCD1200.root\",\"bdt_QCD1500.root\",\"bdt_QCD2000.root\" \"bdt_TT2l.root\",\"bdt_TTlnu.root\",\"bdt_TT4q.root\" \"bdt_Z2*.root\",\"bdt_W4.root\"]\n",
    "background_files = []\n",
    "for pattern in background_patterns:\n",
    "    background_files.extend(glob.glob(os.path.join(input_dir, pattern)))\n",
    "\n",
    "regimes = [\"boosted\"]\n",
    "\n",
    "# --- Data Loader ---\n",
    "def load_tree_data(filename, regime):\n",
    "    with uproot.open(filename) as f:\n",
    "        if regime not in f:\n",
    "            return None\n",
    "        return f[regime].arrays(library=\"np\")\n",
    "\n",
    "def load_data(files, regime, label):\n",
    "    X_all, y_all, w_all = [], [], []\n",
    "    features_used = []\n",
    "\n",
    "    for f in files:\n",
    "        data = load_tree_data(f, regime)\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        features = [k for k in data.keys() if k != \"weight\"]\n",
    "        X = np.column_stack([data[k] for k in features])\n",
    "        y = np.full(X.shape[0], label)\n",
    "        w = data[\"weight\"] * 109080\n",
    "\n",
    "        X_all.append(X)\n",
    "        y_all.append(y)\n",
    "        w_all.append(w)\n",
    "        features_used = features\n",
    "\n",
    "        print(f\"[DEBUG] Loaded {X.shape[0]} samples from {os.path.basename(f)} with label {label}\")\n",
    "\n",
    "    if not X_all:\n",
    "        return None, None, None, []\n",
    "\n",
    "    return (\n",
    "        np.concatenate(X_all),\n",
    "        np.concatenate(y_all),\n",
    "        np.concatenate(w_all),\n",
    "        features_used,\n",
    "    )\n",
    "\n",
    "# --- Main Loop ---\n",
    "for regime in regimes:\n",
    "    print(f\"\\n[INFO] Training BDT for regime: {regime}\")\n",
    "\n",
    "    sig_files = [os.path.join(input_dir, fname) for fname in signal_files_map[regime]]\n",
    "    X_sig, y_sig, w_sig, features = load_data(sig_files, regime, 1)\n",
    "    X_bkg, y_bkg, w_bkg, _ = load_data(background_files, regime, 0)\n",
    "    if X_sig is None or X_bkg is None:\n",
    "        print(f\"[WARNING] Missing data for regime {regime}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    X = np.concatenate([X_sig, X_bkg])\n",
    "    y = np.concatenate([y_sig, y_bkg])\n",
    "    w = np.concatenate([w_sig, w_bkg])\n",
    "\n",
    "    X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "        X, y, w, test_size=0.5, stratify=y\n",
    "    )\n",
    "\n",
    "    df_train = pd.DataFrame(X_train, columns=features)\n",
    "    df_test = pd.DataFrame(X_test, columns=features)\n",
    "    df_train['label'] = y_train\n",
    "    df_test['label'] = y_test\n",
    "\n",
    "    # Correlation matrices\n",
    "       # Correlation matrices WITH percentages\n",
    "    for tag, df in zip([\"train_sig\", \"train_bkg\", \"test_sig\", \"test_bkg\"],\n",
    "                       [df_train[df_train.label == 1], df_train[df_train.label == 0],\n",
    "                        df_test[df_test.label == 1], df_test[df_test.label == 0]]):\n",
    "        corr = df[features].corr()\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, cbar=True,\n",
    "                    annot_kws={\"size\": 8})\n",
    "        plt.title(f\"Correlation Matrix ({regime} - {tag})\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/corr_{regime}_{tag}.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    # Input variable plots\n",
    "    for i, feature in enumerate(features):\n",
    "        plt.figure()\n",
    "        plt.hist(X_sig[:, i], bins=100, density=True, alpha=0.5, label=\"Signal\", color=\"blue\")\n",
    "        plt.hist(X_bkg[:, i], bins=100, density=True, alpha=0.5, label=\"Background\", color=\"red\")\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(\"Normalized Events\")\n",
    "        plt.title(f\"{feature} ({regime})\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/feature_{regime}_{feature}.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "    # GridSearchCV\n",
    "    param_grid = {\n",
    "        \"max_depth\": [1,2, 3, 4],\n",
    "        \"learning_rate\": [0.01, 0.05,0.08,0.09, 0.1],\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"subsample\": [0.5, 0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.6,0.8, 1.0],\n",
    "        \"tree_method\": [\"hist\"],\n",
    "        \"gamma\": [0, 0.5, 1.0],\n",
    "        \"alpha\": [0, 0.1, 1],\n",
    "        \"reg_lambda\": [1, 2]\n",
    "    }\n",
    "        \n",
    "\n",
    "    model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "    search = RandomizedSearchCV(\n",
    "    model, param_distributions=param_grid,\n",
    "    scoring=\"roc_auc\", cv=3, n_iter=300,  # ‚Üê only 100 random combos\n",
    "    verbose=1, n_jobs=-1, random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train, sample_weight=w_train)\n",
    "\n",
    "    model = search.best_estimator_\n",
    "    print(f\"[INFO] Best parameters: {search.best_params_}\")\n",
    "\n",
    "    y_pred_train = model.predict_proba(X_train)[:, 1]\n",
    "    y_pred_test  = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # ROC curve\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_pred_train, sample_weight=w_train)\n",
    "    fpr_test, tpr_test, _   = roc_curve(y_test, y_pred_test, sample_weight=w_test)\n",
    "    auc_train = auc(fpr_train, tpr_train)\n",
    "    auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr_train, tpr_train, label=f\"Train AUC = {auc_train:.3f}\")\n",
    "    plt.plot(fpr_test, tpr_test, label=f\"Test AUC = {auc_test:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve ({regime})\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f\"{output_dir}/roc_{regime}.pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    # Overtraining check\n",
    "    ks_sig = ks_2samp(y_pred_train[y_train == 1], y_pred_test[y_test == 1])\n",
    "    ks_bkg = ks_2samp(y_pred_train[y_train == 0], y_pred_test[y_test == 0])\n",
    "\n",
    "    bins = np.linspace(0, 1, 50)\n",
    "    plt.figure()\n",
    "\n",
    "    # Histogram weights\n",
    "    weights_sig_train = w_train[y_train == 1]\n",
    "    weights_sig_test  = w_test[y_test == 1]\n",
    "    weights_bkg_train = w_train[y_train == 0]\n",
    "    weights_bkg_test  = w_test[y_test == 0]\n",
    "    \n",
    "    # Compute histograms\n",
    "    hist_sig_train, _ = np.histogram(y_pred_train[y_train == 1], bins=bins, weights=weights_sig_train)\n",
    "    hist_sig_test, _  = np.histogram(y_pred_test[y_test == 1], bins=bins, weights=weights_sig_test)\n",
    "    hist_bkg_train, _ = np.histogram(y_pred_train[y_train == 0], bins=bins, weights=weights_bkg_train)\n",
    "    hist_bkg_test, _  = np.histogram(y_pred_test[y_test == 0], bins=bins, weights=weights_bkg_test)\n",
    "    \n",
    "    # Normalize to density\n",
    "    bin_width = bins[1] - bins[0]\n",
    "    hist_sig_train = hist_sig_train / (np.sum(hist_sig_train) * bin_width)\n",
    "    hist_sig_test  = hist_sig_test / (np.sum(hist_sig_test) * bin_width)\n",
    "    hist_bkg_train = hist_bkg_train / (np.sum(hist_bkg_train) * bin_width)\n",
    "    hist_bkg_test  = hist_bkg_test / (np.sum(hist_bkg_test) * bin_width)\n",
    "    \n",
    "    # Plot train (filled)\n",
    "    plt.hist(bins[:-1], bins=bins, weights=hist_sig_train, histtype=\"stepfilled\",\n",
    "             label=\"Sig Train\", color=\"blue\", alpha=0.5)\n",
    "    \n",
    "    plt.hist(bins[:-1], bins=bins, weights=hist_bkg_train, histtype=\"stepfilled\",\n",
    "             label=\"Bkg Train\", color=\"red\", alpha=0.5)\n",
    "    \n",
    "    # Plot test (line)\n",
    "    plt.hist(bins[:-1], bins=bins, weights=hist_sig_test, histtype=\"step\",\n",
    "             label=\"Sig Test\", color=\"blue\", linestyle=\"--\", linewidth=2)\n",
    "    \n",
    "    plt.hist(bins[:-1], bins=bins, weights=hist_bkg_test, histtype=\"step\",\n",
    "             label=\"Bkg Test\", color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "    \n",
    "    # Set axis style\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"BDT Score\")\n",
    "    plt.ylabel(\"Normalized Events\")\n",
    "    plt.title(f\"Overtraining ‚Äî KS p: Sig={ks_sig.pvalue:.3f}, Bkg={ks_bkg.pvalue:.3f}\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set y limit to 1.2√ómax\n",
    "    all_hists = [hist_sig_train, hist_sig_test, hist_bkg_train, hist_bkg_test]\n",
    "    ymax = max([np.max(h) for h in all_hists]) * 10\n",
    "    ymin = max(1e-4, min(np.min(h[h > 0]) for h in all_hists))\n",
    "    plt.ylim([ymin, ymax])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/overtraining_{regime}.pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    # variable importance\n",
    "        # Variable importance ranking (with actual feature names)\n",
    "    importances = model.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Importance\": importances\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    # Save as bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=\"Importance\", y=\"Feature\", data=importance_df, palette=\"viridis\")\n",
    "    plt.title(f\"Feature Importance ({regime})\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/feature_importance_{regime}.pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save as CSV (optional)\n",
    "    importance_df.to_csv(f\"{output_dir}/feature_importance_{regime}.csv\", index=False)\n",
    "\n",
    "    # Efficiency, Rejection, Significance\n",
    "    s_hist, _ = np.histogram(y_pred_test[y_test == 1], bins=bins, weights=w_test[y_test == 1])\n",
    "    b_hist, _ = np.histogram(y_pred_test[y_test == 0], bins=bins, weights=w_test[y_test == 0])\n",
    "    s_cumsum = s_hist[::-1].cumsum()[::-1]\n",
    "    b_cumsum = b_hist[::-1].cumsum()[::-1]\n",
    "\n",
    "    efficiency = s_cumsum / s_cumsum[0]\n",
    "    rejection = 1 - b_cumsum / b_cumsum[0]\n",
    "    significance = s_cumsum / np.sqrt(s_cumsum + b_cumsum )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(bins[:-1], efficiency, label=\"Signal Efficiency\")\n",
    "    plt.plot(bins[:-1], rejection, label=\"Background Rejection\")\n",
    "    plt.plot(bins[:-1], significance, label=\"Significance (S/‚àö(S+B))\")\n",
    "    plt.xlabel(\"BDT Cut\")\n",
    "    plt.ylabel(\"Metric\")\n",
    "    plt.title(f\"Performance Metrics vs. BDT Cut ({regime})\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f\"{output_dir}/eff_rej_significance_{regime}.pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    model.save_model(f\"{output_dir}/bdt_model_{regime}.json\")\n",
    "    print(f\"[DONE] {regime} ‚Äî AUC: {auc_test:.3f}, Max Significance: {np.max(significance):.2f}\")\n",
    "    # --- Cross-validation consistency check ---\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    auc_per_fold = []\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n",
    "        X_tr, X_te = X[train_idx], X[test_idx]\n",
    "        y_tr, y_te = y[train_idx], y[test_idx]\n",
    "        w_tr, w_te = w[train_idx], w[test_idx]\n",
    "    \n",
    "        model_cv = xgb.XGBClassifier(**search.best_params_, eval_metric=\"logloss\")\n",
    "        model_cv.fit(X_tr, y_tr, sample_weight=w_tr)\n",
    "    \n",
    "        y_pred_cv = model_cv.predict_proba(X_te)[:, 1]\n",
    "        auc_cv = roc_auc_score(y_te, y_pred_cv, sample_weight=w_te)\n",
    "        auc_per_fold.append(auc_cv)\n",
    "        print(f\"[CV Fold {fold+1}] AUC = {auc_cv:.4f}\")\n",
    "    \n",
    "    # Plot AUC vs Fold\n",
    "    plt.figure()\n",
    "    plt.plot(range(1, 6), auc_per_fold, marker=\"o\", linestyle=\"-\", label=\"Fold AUC\")\n",
    "    plt.xlabel(\"CV Fold\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.ylim(0.9, 1)\n",
    "    plt.grid()\n",
    "    plt.savefig(f\"{output_dir}/cv_auc_vs_fold_{regime}.pdf\")\n",
    "    plt.close()\n",
    "    \n",
    "    # --- N-1 feature tests ---\n",
    "    n1_results = []\n",
    "    for drop_feature in features:\n",
    "        X_train_n1 = pd.DataFrame(X_train, columns=features).drop(columns=[drop_feature]).values\n",
    "        X_test_n1 = pd.DataFrame(X_test, columns=features).drop(columns=[drop_feature]).values\n",
    "    \n",
    "        model_n1 = xgb.XGBClassifier(**search.best_params_, eval_metric=\"logloss\")\n",
    "        model_n1.fit(X_train_n1, y_train, sample_weight=w_train)\n",
    "        y_pred_n1 = model_n1.predict_proba(X_test_n1)[:, 1]\n",
    "        auc_n1 = roc_auc_score(y_test, y_pred_n1, sample_weight=w_test)\n",
    "        auc_drop = auc_test - auc_n1\n",
    "        n1_results.append((drop_feature, auc_n1, auc_drop))\n",
    "        print(f\"[N-1] Dropped: {drop_feature:20} | AUC: {auc_n1:.4f} | AUC Drop: {auc_drop:.4f}\")\n",
    "    \n",
    "    # Save to CSV\n",
    "    n1_df = pd.DataFrame(n1_results, columns=[\"Dropped Feature\", \"AUC\", \"AUC Drop\"])\n",
    "    n1_df.to_csv(f\"{output_dir}/n1_auc_drop_{regime}.csv\", index=False)\n",
    "    \n",
    "    # Plot AUC drop from N-1\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=n1_df.sort_values(\"AUC Drop\", ascending=False), x=\"AUC Drop\", y=\"Dropped Feature\", palette=\"viridis\")\n",
    "    plt.title(f\"AUC Drop per N-1 Feature Removal ({regime})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/n1_auc_drop_{regime}.pdf\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aee843-512c-429c-841d-a433c1d18b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
