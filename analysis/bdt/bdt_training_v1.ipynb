{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6502d9b-9c66-4f08-8d26-a9fab1f0e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import uproot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# --- Config ---\n",
    "input_dir = \"/Users/artemis/Desktop/bdt/bdt_inputs\"\n",
    "output_dir = \"/Users/artemis/Desktop/bdt/bdt_results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define signal files per regime\n",
    "signal_files_map = {\n",
    "    \"boosted\": [\n",
    "        \"bdt_ZH12.root\", \"bdt_ZH15.root\"\n",
    "    ],\n",
    "    \"merged\": [\n",
    "        \"bdt_ZH20.root\", \"bdt_ZH25.root\"\n",
    "    ],\n",
    "    \"resolved\": [\n",
    "        \"bdt_ZH30.root\", \"bdt_ZH40.root\", \"bdt_ZH50.root\", \"bdt_ZH60.root\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Glob all background files (QCD, TT, Zto)\n",
    "background_patterns = [\"bdt_QCD*.root\", \"bdt_TT*.root\", \"bdt_Zto*.root\"]\n",
    "background_files = []\n",
    "for pattern in background_patterns:\n",
    "    background_files.extend(glob.glob(os.path.join(input_dir, pattern)))\n",
    "\n",
    "regimes = [\"boosted\", \"merged\", \"resolved\"]\n",
    "\n",
    "# --- Data Loader ---\n",
    "def load_tree_data(filename, regime):\n",
    "    with uproot.open(filename) as f:\n",
    "        if regime not in f:\n",
    "            return None\n",
    "        return f[regime].arrays(library=\"np\")\n",
    "\n",
    "def load_data(files, regime, label, weight_scale=180000):\n",
    "    X_all, y_all, w_all = [], [], []\n",
    "    features_used = []\n",
    "\n",
    "    for f in files:\n",
    "        data = load_tree_data(f, regime)\n",
    "        if data is None:\n",
    "            continue\n",
    "\n",
    "        features = [k for k in data.keys() if k != \"weight\"]\n",
    "        X = np.column_stack([data[k] for k in features])\n",
    "        y = np.full(X.shape[0], label)\n",
    "        w = data[\"weight\"] * weight_scale\n",
    "\n",
    "        X_all.append(X)\n",
    "        y_all.append(y)\n",
    "        w_all.append(w)\n",
    "        features_used = features\n",
    "\n",
    "        print(f\"[DEBUG] Loaded {X.shape[0]} samples from {os.path.basename(f)} with label {label}\")\n",
    "\n",
    "    if not X_all:\n",
    "        return None, None, None, []\n",
    "\n",
    "    return (\n",
    "        np.concatenate(X_all),\n",
    "        np.concatenate(y_all),\n",
    "        np.concatenate(w_all),\n",
    "        features_used,\n",
    "    )\n",
    "\n",
    "# --- Main Loop ---\n",
    "for regime in regimes:\n",
    "    print(f\"\\n[INFO] Training BDT for regime: {regime}\")\n",
    "\n",
    "    sig_files = [os.path.join(input_dir, fname) for fname in signal_files_map[regime]]\n",
    "    X_sig, y_sig, w_sig, features = load_data(sig_files, regime, 1)\n",
    "    X_bkg, y_bkg, w_bkg, _ = load_data(background_files, regime, 0)\n",
    "    if X_sig is None or X_bkg is None:\n",
    "        print(f\"[WARNING] Missing data for regime {regime}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    X = np.concatenate([X_sig, X_bkg])\n",
    "    y = np.concatenate([y_sig, y_bkg])\n",
    "    w = np.concatenate([w_sig, w_bkg])\n",
    "\n",
    "    X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(\n",
    "        X, y, w, test_size=0.5, stratify=y\n",
    "    )\n",
    "\n",
    "    df_train = pd.DataFrame(X_train, columns=features)\n",
    "    df_test = pd.DataFrame(X_test, columns=features)\n",
    "    df_train['label'] = y_train\n",
    "    df_test['label'] = y_test\n",
    "\n",
    "    # Correlation matrices\n",
    "       # Correlation matrices WITH percentages\n",
    "    for tag, df in zip([\"train_sig\", \"train_bkg\", \"test_sig\", \"test_bkg\"],\n",
    "                       [df_train[df_train.label == 1], df_train[df_train.label == 0],\n",
    "                        df_test[df_test.label == 1], df_test[df_test.label == 0]]):\n",
    "        corr = df[features].corr()\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", square=True, cbar=True,\n",
    "                    annot_kws={\"size\": 8})\n",
    "        plt.title(f\"Correlation Matrix ({regime} - {tag})\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/corr_{regime}_{tag}.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    # Input variable plots\n",
    "    for i, feature in enumerate(features):\n",
    "        plt.figure()\n",
    "        plt.hist(X_sig[:, i], bins=100, density=True, alpha=0.5, label=\"Signal\", color=\"blue\")\n",
    "        plt.hist(X_bkg[:, i], bins=100, density=True, alpha=0.5, label=\"Background\", color=\"red\")\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(\"Normalized Events\")\n",
    "        plt.title(f\"{feature} ({regime})\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{output_dir}/feature_{regime}_{feature}.pdf\")\n",
    "        plt.close()\n",
    "\n",
    "    # GridSearchCV\n",
    "    param_grid = {\n",
    "        \"max_depth\": [1,2, 3, 4],\n",
    "        \"learning_rate\": [0.01, 0.05,0.08,0.09, 0.1],\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"subsample\": [0.5, 0.8, 1.0],\n",
    "        \"colsample_bytree\": [0.6,0.8, 1.0],\n",
    "        \"tree_method\": [\"hist\"],\n",
    "        \"gamma\": [0, 0.5, 1.0],\n",
    "        \"alpha\": [0, 0.1, 1],\n",
    "        \"reg_lambda\": [1, 2]\n",
    "    }\n",
    "        \n",
    "\n",
    "    model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"logloss\")\n",
    "    grid = GridSearchCV(model, param_grid, scoring=\"roc_auc\", cv=3, verbose=1, n_jobs=-1)\n",
    "    grid.fit(X_train, y_train, sample_weight=w_train)\n",
    "\n",
    "    model = grid.best_estimator_\n",
    "    print(f\"[INFO] Best parameters: {grid.best_params_}\")\n",
    "\n",
    "    y_pred_train = model.predict_proba(X_train)[:, 1]\n",
    "    y_pred_test  = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # ROC curve\n",
    "    fpr_train, tpr_train, _ = roc_curve(y_train, y_pred_train, sample_weight=w_train)\n",
    "    fpr_test, tpr_test, _   = roc_curve(y_test, y_pred_test, sample_weight=w_test)\n",
    "    auc_train = auc(fpr_train, tpr_train)\n",
    "    auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr_train, tpr_train, label=f\"Train AUC = {auc_train:.3f}\")\n",
    "    plt.plot(fpr_test, tpr_test, label=f\"Test AUC = {auc_test:.3f}\")\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"ROC Curve ({regime})\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f\"{output_dir}/roc_{regime}.pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    # Overtraining check\n",
    "    ks_sig = ks_2samp(y_pred_train[y_train == 1], y_pred_test[y_test == 1])\n",
    "    ks_bkg = ks_2samp(y_pred_train[y_train == 0], y_pred_test[y_test == 0])\n",
    "\n",
    "    bins = np.linspace(0, 1, 100)\n",
    "    plt.figure()\n",
    "    plt.hist(y_pred_train[y_train == 1], bins=bins, density=True, histtype='step', label=\"Sig train\", color=\"blue\")\n",
    "    plt.hist(y_pred_test[y_test == 1], bins=bins, density=True, histtype='step', linestyle='--', label=\"Sig test\", color=\"blue\")\n",
    "    plt.hist(y_pred_train[y_train == 0], bins=bins, density=True, histtype='step', label=\"Bkg train\", color=\"red\")\n",
    "    plt.hist(y_pred_test[y_test == 0], bins=bins, density=True, histtype='step', linestyle='--', label=\"Bkg test\", color=\"red\")\n",
    "    plt.title(f\"Overtraining â€” KS p: Sig={ks_sig.pvalue:.3f}, Bkg={ks_bkg.pvalue:.3f}\")\n",
    "    plt.xlabel(\"BDT Score\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f\"{output_dir}/overtraining_{regime}.pdf\")\n",
    "    plt.close()\n",
    "    # variable importance\n",
    "        # Variable importance ranking (with actual feature names)\n",
    "    importances = model.feature_importances_\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": features,\n",
    "        \"Importance\": importances\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    # Save as bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=\"Importance\", y=\"Feature\", data=importance_df, palette=\"viridis\")\n",
    "    plt.title(f\"Feature Importance ({regime})\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output_dir}/feature_importance_{regime}.pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    # Save as CSV (optional)\n",
    "    importance_df.to_csv(f\"{output_dir}/feature_importance_{regime}.csv\", index=False)\n",
    "\n",
    "    # Efficiency, Rejection, Significance\n",
    "    s_hist, _ = np.histogram(y_pred_test[y_test == 1], bins=bins, weights=w_test[y_test == 1])\n",
    "    b_hist, _ = np.histogram(y_pred_test[y_test == 0], bins=bins, weights=w_test[y_test == 0])\n",
    "    s_cumsum = s_hist[::-1].cumsum()[::-1]\n",
    "    b_cumsum = b_hist[::-1].cumsum()[::-1]\n",
    "\n",
    "    efficiency = s_cumsum / s_cumsum[0]\n",
    "    rejection = 1 - b_cumsum / b_cumsum[0]\n",
    "    significance = s_cumsum / np.sqrt(s_cumsum + b_cumsum )\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(bins[:-1], efficiency, label=\"Signal Efficiency\")\n",
    "    plt.plot(bins[:-1], rejection, label=\"Background Rejection\")\n",
    "    plt.plot(bins[:-1], significance, label=\"Significance (S/âˆš(S+B))\")\n",
    "    plt.xlabel(\"BDT Cut\")\n",
    "    plt.ylabel(\"Metric\")\n",
    "    plt.title(f\"Performance Metrics vs. BDT Cut ({regime})\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f\"{output_dir}/eff_rej_significance_{regime}.pdf\")\n",
    "    plt.close()\n",
    "\n",
    "    model.save_model(f\"{output_dir}/bdt_model_{regime}.json\")\n",
    "    print(f\"[DONE] {regime} â€” AUC: {auc_test:.3f}, Max Significance: {np.max(significance):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0354a58-9f26-4ca0-b197-0ade8dc6ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd502c8-58dd-4d48-be56-85e4c0f07f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
